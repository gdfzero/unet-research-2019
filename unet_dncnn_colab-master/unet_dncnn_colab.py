# -*- coding: utf-8 -*-
"""unet_dncnn_colab.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mgYtNoCQ7NMC8iTQwqB00stxGl6QY4db
"""

from google.colab import drive
drive.mount('/content/drive')

import os

import zipfile
import random
import tensorflow as tf
from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from shutil import copyfile
import numpy as np

import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from keras.layers import Concatenate
from keras.models import Sequential
import keras
from keras.layers import Conv2D, MaxPooling2D, Input, Dense, BatchNormalization, Activation
from keras.models import Model
import matplotlib.image as mpimg
from glob import glob
from keras.layers.convolutional import Conv2DTranspose
from keras.layers import concatenate
import struct

# print(len(os.listdir('/content/drive/My Drive/Colab Notebooks/CT_data/sparseview_60/train')))
# print(len(os.listdir('/content/drive/My Drive/Colab Notebooks/CT_data/ndct/train')))
# # 3600
# # 3600

# print(len(os.listdir('/content/drive/My Drive/Colab Notebooks/CT_data/sparseview_60/test/')))
# print(len(os.listdir('/content/drive/My Drive/Colab Notebooks/CT_data/ndct/test/')))
# # 354
# # 354

# ndct = sorted(glob('/content/drive/My Drive/Colab Notebooks/CT_data/ndct/train/*'))
# ldct = sorted(glob('/content/drive/My Drive/Colab Notebooks/CT_data/sparseview_60/train/*'))

# ndct_test = sorted(glob('/content/drive/My Drive/Colab Notebooks/CT_data/ndct/test/*'))
# ldct_test = sorted(glob('/content/drive/My Drive/Colab Notebooks/CT_data/sparseview_60/test/*'))

# print(len(ndct))
# print(len(ldct))
# print(len(ndct_test))
# print(len(ldct_test))

def cal_psnr(im1, im2):
    # assert pixel value range is 0-255 and type is uint8
    mse = ((im1.astype(np.float) - im2.astype(np.float)) ** 2).mean()
    maxval = np.amax(im1)
    psnr = 10 * np.log10(maxval ** 2 / mse)
    return psnr

def tf_psnr(im1, im2):
    # assert pixel value range is 0-1
    #mse = tf.losses.mean_squared_error(labels=im2 * 255.0, predictions=im1 * 255.0)
    mse = tf.compat.v1.losses.mean_squared_error(labels=im2 * 255.0, predictions=im1 * 255.0)
    return 10.0 * (tf.log(255.0 ** 2 / mse) / tf.log(10.0))



# ndct_imgs_train = []
# for i in range(0, len(ndct)):                                                                                                                                      
# #for i in range(0, 1600):
#     f = open(ndct[i],'rb')
#     a = np.fromfile(f, np.float32)
#     ndct_imgs_train.append(a)
#     f.close()
# print("len(ndct_imgs_train)....: ",len(ndct_imgs_train))

# ldct_imgs_train = []
# for i in range(0, len(ldct)):
# #for i in range(0, 1600):
#     f = open(ldct[i],'rb')
#     a = np.fromfile(f, np.float32)
#     ldct_imgs_train.append(a)
#     f.close()
# print("len(ldct_imgs_train)....: ",len(ldct_imgs_train))

# ndct_imgs_test = []
# for i in range(0, len(ndct_test)):
# #for i in range(0, 10):
#     f = open(ndct_test[i],'rb')
#     a = np.fromfile(f, np.float32)
#     ndct_imgs_test.append(a)
#     f.close()
# print("len(ndct_imgs_test)....: ",len(ndct_imgs_test))

# # load the image
# ldct_imgs_test = []
# for i in range(0, len(ldct_test)):
# #for i in range(0, 10):
#     f = open(ldct_test[i],'rb')
#     a = np.fromfile(f, np.float32)
#     ldct_imgs_test.append(a)
#     f.close()
# print("len(ldct_imgs_test)....: ",len(ldct_imgs_test))

# ldct_train = np.asarray(ldct_imgs_train)
# ndct_train = np.asarray(ndct_imgs_train)

# ldct_train = ldct_train.reshape(3600,512,512,1)
# ndct_train = ndct_train.reshape(3600,512,512,1)

# ldct_test = np.asarray(ldct_imgs_test)
# ndct_test = np.asarray(ndct_imgs_test)

# ldct_test = ldct_test.reshape(len(ldct_imgs_test),512,512,1)
# ndct_test = ndct_test.reshape(len(ldct_imgs_test),512,512,1)

# print(ldct_train.shape)
# print(ndct_train.shape)
# print(ldct_test.shape)
# print(ndct_test.shape)

# np.save('sparseview_60_train', ldct_train) # save the file as "sparseview_60_train.npy" 
# np.save('ndct_train', ndct_train) # save the file as "ndct_train.npy" 

# np.save('sparseview_60_test', ldct_test) # save the file as "sparseview_60_test.npy" 
# np.save('ndct_test', ndct_test) # save the file as "ndct_test.npy"

sparseview_60_train = np.load('/content/drive/My Drive/Colab Notebooks/dncnn_keras_colab_notebook/sparseview_60_train.npy') # loads saved array into variable sparseview_60_train.
ndct_train = np.load('/content/drive/My Drive/Colab Notebooks/dncnn_keras_colab_notebook/ndct_train.npy') # loads saved array into variable ndct_train.
sparseview_60_test = np.load('/content/drive/My Drive/Colab Notebooks/dncnn_keras_colab_notebook/sparseview_60_test.npy') # loads saved array into variable sparseview_60_test.
ndct_test = np.load('/content/drive/My Drive/Colab Notebooks/dncnn_keras_colab_notebook/ndct_test.npy') # loads saved array into variable ndct_test.

# sparseview_60_train = np.load('sparseview_60_train.npy') # loads saved array into variable sparseview_60_train.
# ndct_train = np.load('ndct_train.npy') # loads saved array into variable ndct_train.
# sparseview_60_test = np.load('sparseview_60_test.npy') # loads saved array into variable sparseview_60_test.
# ndct_test = np.load('ndct_test.npy') # loads saved array into variable ndct_test.

class LossHistory(keras.callbacks.Callback):
    def on_train_begin(self, logs={}):
        self.losses = []

    def on_batch_end(self, batch, logs={}):
        self.losses.append(logs.get('loss'))
history = LossHistory()

"""Basic UNet model"""

inputs = Input((None, None,1))

c1 = Conv2D(8, (3, 3), activation='relu', padding='same') (inputs)
c1 = Conv2D(8, (3, 3), activation='relu', padding='same') (c1)
p1 = MaxPooling2D((2, 2)) (c1)

c2 = Conv2D(16, (3, 3), activation='relu', padding='same') (p1)
c2 = Conv2D(16, (3, 3), activation='relu', padding='same') (c2)
p2 = MaxPooling2D((2, 2)) (c2)

c3 = Conv2D(32, (3, 3), activation='relu', padding='same') (p2)
c3 = Conv2D(32, (3, 3), activation='relu', padding='same') (c3)
p3 = MaxPooling2D((2, 2)) (c3)


c5 = Conv2D(64, (3, 3), activation='relu', padding='same') (p3)
c5 = Conv2D(64, (3, 3), activation='relu', padding='same') (c5)
p5 = MaxPooling2D(pool_size=(2, 2)) (c5)

c55 = Conv2D(128, (3, 3), activation='relu', padding='same') (p5)
c55 = Conv2D(128, (3, 3), activation='relu', padding='same') (c55)

u6 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c55)
u6 = concatenate([u6, c5])
c6 = Conv2D(64, (3, 3), activation='relu', padding='same') (u6)
c6 = Conv2D(64, (3, 3), activation='relu', padding='same') (c6)


u7 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c6)
u7 = concatenate([u7, c3])
c7 = Conv2D(32, (3, 3), activation='relu', padding='same') (u7)
c7 = Conv2D(32, (3, 3), activation='relu', padding='same') (c7)

u8 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c7)
u8 = concatenate([u8, c2])
c8 = Conv2D(16, (3, 3), activation='relu', padding='same') (u8)
c8 = Conv2D(16, (3, 3), activation='relu', padding='same') (c8)

u9 = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (c8)
u9 = concatenate([u9, c1], axis=3)
c9 = Conv2D(8, (3, 3), activation='relu', padding='same') (u9)
c9 = Conv2D(8, (3, 3), activation='relu', padding='same') (c9)

output_img = Conv2D(1, (1, 1)) (c9)
subtracted = keras.layers.Subtract()([inputs, output_img])


model = Model(inputs=[inputs], outputs=[subtracted])
model.compile(optimizer='adam', loss='mse', metrics=[tf_psnr])



"""Validation is set to zero because I wanted to use all my data to train and from previouse training experience I learned that the model doesn't overfit in 50 epochs."""

model.fit(sparseview_60_train, ndct_train, validation_split=0, batch_size=30, epochs=50, callbacks=[history])

reconstructed = model.predict(sparseview_60_test)
psnr = cal_psnr(ndct_test, reconstructed)
print("psnr 50 epochs.....",psnr)

"""Original UNet (without bn)
psnr 50 epochs..... 37.96383834661668
"""

from PIL import Image

a = reconstructed[12].reshape(512, 512)
scalef = np.amax(a)
a = np.clip(255 * a/scalef, 0, 255).astype('uint8')
#result = Image.fromarray((a * 255).astype(np.uint8))                                                                                                
result = Image.fromarray((a).astype(np.uint8))
result.save('rec_orig_0_50.png')
result.save('/content/drive/My Drive/Colab Notebooks/dncnn_keras_colab_notebook/rec_orig_0_50.png')

"""UNet model with batch normalization"""

inputs = Input((None, None,1))
c1 = Conv2D(8, (3, 3), padding='same') (inputs)
c1 = BatchNormalization()(c1)
c1 = Activation('relu')(c1)

c1 = Conv2D(8, (3, 3), padding='same') (c1)
c1 = BatchNormalization()(c1)
c1 = Activation('relu')(c1)

p1 = MaxPooling2D((2, 2)) (c1)

c2 = Conv2D(16, (3, 3), padding='same') (p1)
c2 = BatchNormalization()(c2)
c2 = Activation('relu')(c2)

c2 = Conv2D(16, (3, 3), padding='same') (c2)
c2 = BatchNormalization()(c2)
c2 = Activation('relu')(c2)

p2 = MaxPooling2D((2, 2)) (c2)

c3 = Conv2D(32, (3, 3), padding='same') (p2)
c3 = BatchNormalization()(c3)
c3 = Activation('relu')(c3)

c3 = Conv2D(32, (3, 3), padding='same') (c3)
c3 = BatchNormalization()(c3)
c3 = Activation('relu')(c3)

p3 = MaxPooling2D((2, 2)) (c3)

c5 = Conv2D(64, (3, 3), padding='same') (p3)
c5 = BatchNormalization()(c5)
c5 = Activation('relu')(c5)

c5 = Conv2D(64, (3, 3), padding='same') (c5)
c5 = BatchNormalization()(c5)
c5 = Activation('relu')(c5)

p5 = MaxPooling2D(pool_size=(2, 2)) (c5)

c55 = Conv2D(128, (3, 3), padding='same') (p5)
c55 = BatchNormalization()(c55)
c55 = Activation('relu')(c55)

c55 = Conv2D(128, (3, 3), padding='same') (c55)
c55 = BatchNormalization()(c55)
c55 = Activation('relu')(c55)

u6 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c55)
u6 = concatenate([u6, c5])

c6 = Conv2D(64, (3, 3), padding='same') (u6)
c6 = BatchNormalization()(c6)
c6 = Activation('relu')(c6)

c6 = Conv2D(64, (3, 3), padding='same') (c6)
c6 = BatchNormalization()(c6)
c6 = Activation('relu')(c6)

u7 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c6)
u7 = concatenate([u7, c3])

c7 = Conv2D(32, (3, 3), padding='same') (u7)
c7 = BatchNormalization()(c7)
c7 = Activation('relu')(c7)

c7 = Conv2D(32, (3, 3), padding='same') (c7)
c7 = BatchNormalization()(c7)
c7 = Activation('relu')(c7)

u8 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c7)
u8 = concatenate([u8, c2])

c8 = Conv2D(16, (3, 3), padding='same') (u8)
c8 = BatchNormalization()(c8)
c8 = Activation('relu')(c8)

c8 = Conv2D(16, (3, 3), padding='same') (c8)
c8 = BatchNormalization()(c8)
c8 = Activation('relu')(c8)

u9 = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (c8)
u9 = concatenate([u9, c1], axis=3)

c9 = Conv2D(8, (3, 3), padding='same') (u9)
c9 = BatchNormalization()(c9)
c9 = Activation('relu')(c9)

c9 = Conv2D(8, (3, 3), padding='same') (c9)
c9 = BatchNormalization()(c9)
c9 = Activation('relu')(c9)

output_img = Conv2D(1, (1, 1)) (c9)
subtracted = keras.layers.Subtract()([inputs, output_img])


bn_model = Model(inputs=[inputs], outputs=[subtracted])
bn_model.compile(optimizer='adam', loss='mse', metrics=[tf_psnr])

bn_model.fit(sparseview_60_train, ndct_train, validation_split=0, batch_size=30, epochs=50, callbacks=[history])
reconstructed = bn_model.predict(sparseview_60_test)
psnr = cal_psnr(ndct_test, reconstructed)
print("psnr 50 epochs.....",psnr)

"""UNet with bn psnr 50 epochs..... 35.87923776473124"""

#from PIL import Image

a = reconstructed[12].reshape(512, 512)
scalef = np.amax(a)
a = np.clip(255 * a/scalef, 0, 255).astype('uint8')
#result = Image.fromarray((a * 255).astype(np.uint8))                                                                                                
result = Image.fromarray((a).astype(np.uint8))
result.save('rec_unet_bn_12_50.png')
result.save('/content/drive/My Drive/Colab Notebooks/dncnn_keras_colab_notebook/rec_unet_bn_12_50.png')

"""Added axis to the batch normalization c1 = BatchNormalization(axis=-1)(c1) but negative one didn't produce goog results. I expected to see the same output as above with axis=-1 but the output was very bad. Decided to change axis=-2 and training went faster. We are suppose to normalize per channel and I need to figure out why axis=-1 is not working out for this problem. I tried axis=-2 just to see what will happen.  axis=-2 is a wrong way to do batch normalization."""

inputs = Input((None, 512, 1))
c1 = Conv2D(8, (3, 3), padding='same') (inputs)
c1 = BatchNormalization(axis=-2)(c1)
c1 = Activation('relu')(c1)

c1 = Conv2D(8, (3, 3), padding='same') (c1)
c1 = BatchNormalization(axis=-2)(c1)
c1 = Activation('relu')(c1)

p1 = MaxPooling2D((2, 2)) (c1)

c2 = Conv2D(16, (3, 3), padding='same') (p1)
c2 = BatchNormalization(axis=-2)(c2)
c2 = Activation('relu')(c2)

c2 = Conv2D(16, (3, 3), padding='same') (c2)
c2 = BatchNormalization(axis=-2)(c2)
c2 = Activation('relu')(c2)

p2 = MaxPooling2D((2, 2)) (c2)

c3 = Conv2D(32, (3, 3), padding='same') (p2)
c3 = BatchNormalization(axis=-2)(c3)
c3 = Activation('relu')(c3)

c3 = Conv2D(32, (3, 3), padding='same') (c3)
c3 = BatchNormalization(axis=-2)(c3)
c3 = Activation('relu')(c3)

p3 = MaxPooling2D((2, 2)) (c3)

c5 = Conv2D(64, (3, 3), padding='same') (p3)
c5 = BatchNormalization(axis=-2)(c5)
c5 = Activation('relu')(c5)

c5 = Conv2D(64, (3, 3), padding='same') (c5)
c5 = BatchNormalization(axis=-2)(c5)
c5 = Activation('relu')(c5)

p5 = MaxPooling2D(pool_size=(2, 2)) (c5)

c55 = Conv2D(128, (3, 3), padding='same') (p5)
c55 = BatchNormalization(axis=-2)(c55)
c55 = Activation('relu')(c55)

c55 = Conv2D(128, (3, 3), padding='same') (c55)
c55 = BatchNormalization(axis=-2)(c55)
c55 = Activation('relu')(c55)

u6 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c55)
u6 = concatenate([u6, c5])

c6 = Conv2D(64, (3, 3), padding='same') (u6)
c6 = BatchNormalization(axis=-2)(c6)
c6 = Activation('relu')(c6)

c6 = Conv2D(64, (3, 3), padding='same') (c6)
c6 = BatchNormalization(axis=-2)(c6)
c6 = Activation('relu')(c6)

u7 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c6)
u7 = concatenate([u7, c3])

c7 = Conv2D(32, (3, 3), padding='same') (u7)
c7 = BatchNormalization(axis=-2)(c7)
c7 = Activation('relu')(c7)

c7 = Conv2D(32, (3, 3), padding='same') (c7)
c7 = BatchNormalization(axis=-2)(c7)
c7 = Activation('relu')(c7)

u8 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c7)
u8 = concatenate([u8, c2])

c8 = Conv2D(16, (3, 3), padding='same') (u8)
c8 = BatchNormalization(axis=-2)(c8)
c8 = Activation('relu')(c8)

c8 = Conv2D(16, (3, 3), padding='same') (c8)
c8 = BatchNormalization(axis=-2)(c8)
c8 = Activation('relu')(c8)

u9 = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (c8)
u9 = concatenate([u9, c1], axis=3)

c9 = Conv2D(8, (3, 3), padding='same') (u9)
c9 = BatchNormalization(axis=-2)(c9)
c9 = Activation('relu')(c9)

c9 = Conv2D(8, (3, 3), padding='same') (c9)
c9 = BatchNormalization(axis=-2)(c9)
c9 = Activation('relu')(c9)

output_img = Conv2D(1, (1, 1)) (c9)
subtracted = keras.layers.Subtract()([inputs, output_img])


unet_bn_axis_model = Model(inputs=[inputs], outputs=[subtracted])
unet_bn_axis_model.compile(optimizer='adam', loss='mse', metrics=[tf_psnr])

unet_bn_axis_model.fit(sparseview_60_train, ndct_train, validation_split=0, batch_size=30, epochs=50, callbacks=[history])

reconstructed = unet_bn_axis_model.predict(sparseview_60_test)
psnr = cal_psnr(ndct_test, reconstructed)
print("psnr 50 epochs.....",psnr)

"""Unet with batch normalization on axis = -2 psnr 50 epochs..... 36.74015266493417"""

#from PIL import Image

a = reconstructed[12].reshape(512, 512)
scalef = np.amax(a)
a = np.clip(255 * a/scalef, 0, 255).astype('uint8')
#result = Image.fromarray((a * 255).astype(np.uint8))                                                                                                
result = Image.fromarray((a).astype(np.uint8))
result.save('rec_unet_bn_axis_12_50.png')
result.save('/content/drive/My Drive/Colab Notebooks/dncnn_keras_colab_notebook/rec_unet_bn_axis_12_50.png')

"""Because of memory restrictions Dncnn model has batch size 5. As we can see below the training is very slow."""

inputs = Input((None, None,1))

c1 = Conv2D(64, (3, 3), activation='relu', padding='same') (inputs)
c1 = Conv2D(64, (3, 3), activation='relu', padding='same') (c1)

c1 = Conv2D(64, (3, 3), activation='relu', padding='same') (c1)
c1 = Conv2D(64, (3, 3), activation='relu', padding='same') (c1)


c1 = Conv2D(64, (3, 3), activation='relu', padding='same') (c1)
c1 = Conv2D(64, (3, 3), activation='relu', padding='same') (c1)


c1 = Conv2D(64, (3, 3), activation='relu', padding='same') (c1)
c1 = Conv2D(64, (3, 3), activation='relu', padding='same') (c1)


c1 = Conv2D(64, (3, 3), activation='relu', padding='same') (c1)
c1 = Conv2D(64, (3, 3), activation='relu', padding='same') (c1)


c1 = Conv2D(64, (3, 3), activation='relu', padding='same') (c1)
c1 = Conv2D(64, (3, 3), activation='relu', padding='same') (c1)

c1 = Conv2D(64, (3, 3), activation='relu', padding='same') (c1)
c1 = Conv2D(64, (3, 3), activation='relu', padding='same') (c1)


c1 = Conv2D(64, (3, 3), activation='relu', padding='same') (c1)
c1 = Conv2D(64, (3, 3), activation='relu', padding='same') (c1)

output_img = Conv2D(1, (1, 1)) (c1)
subtracted = keras.layers.Subtract()([inputs, output_img])


dncnn_model = Model(inputs=[inputs], outputs=[subtracted])
dncnn_model.compile(optimizer='adam', loss='mse', metrics=[tf_psnr])

dncnn_model.fit(sparseview_60_train, ndct_train, validation_split=0, batch_size=5, epochs=50, callbacks=[history])

reconstructed = dncnn_model.predict(sparseview_60_test)
psnr = cal_psnr(ndct_test, reconstructed)
print("psnr 50 epochs.....",psnr)

#from PIL import Image

a = reconstructed[0].reshape(512, 512)
scalef = np.amax(a)
a = np.clip(255 * a/scalef, 0, 255).astype('uint8')
#result = Image.fromarray((a * 255).astype(np.uint8))                                                                                                
result = Image.fromarray((a).astype(np.uint8))
result.save('rec_dncnn_50.png')
result.save('/content/drive/My Drive/Colab Notebooks/dncnn_keras_colab_notebook/rec_dncnn_50.png')

"""dncnn with batch normalization"""

inputs = Input((None, None,1))
#layer 1
c1 = Conv2D(64, (3, 3), activation='relu', padding='same') (inputs)
c1 = BatchNormalization()(c1)
c1 = Activation('relu')(c1)
#layer 2
c1 = Conv2D(64, (3, 3), activation='relu', padding='same') (c1)
c1 = BatchNormalization()(c1)
c1 = Activation('relu')(c1)
#layer 3
c1 = Conv2D(64, (3, 3), activation='relu', padding='same') (c1)
c1 = BatchNormalization()(c1)
c1 = Activation('relu')(c1)
#layer 4
c1 = Conv2D(64, (3, 3), activation='relu', padding='same') (c1)
c1 = BatchNormalization()(c1)
c1 = Activation('relu')(c1)
#layer 5
c1 = Conv2D(64, (3, 3), activation='relu', padding='same') (c1)
c1 = BatchNormalization()(c1)
c1 = Activation('relu')(c1)
#layer 6
c1 = Conv2D(64, (3, 3), activation='relu', padding='same') (c1)
c1 = BatchNormalization()(c1)
c1 = Activation('relu')(c1)
#layer 7
c1 = Conv2D(64, (3, 3), activation='relu', padding='same') (c1)
c1 = BatchNormalization()(c1)
c1 = Activation('relu')(c1)
#layer 8
c1 = Conv2D(64, (3, 3), activation='relu', padding='same') (c1)
c1 = BatchNormalization()(c1)
c1 = Activation('relu')(c1)
#layer 9
c1 = Conv2D(64, (3, 3), activation='relu', padding='same') (c1)
c1 = BatchNormalization()(c1)
c1 = Activation('relu')(c1)
#layer 10
c1 = Conv2D(64, (3, 3), activation='relu', padding='same') (c1)
c1 = BatchNormalization()(c1)
c1 = Activation('relu')(c1)
#layer 11
c1 = Conv2D(64, (3, 3), activation='relu', padding='same') (c1)
c1 = BatchNormalization()(c1)
c1 = Activation('relu')(c1)
#layer 12
c1 = Conv2D(64, (3, 3), activation='relu', padding='same') (c1)
c1 = BatchNormalization()(c1)
c1 = Activation('relu')(c1)
#layer 13
c1 = Conv2D(64, (3, 3), activation='relu', padding='same') (c1)
c1 = BatchNormalization()(c1)
c1 = Activation('relu')(c1)
#layer 14
c1 = Conv2D(64, (3, 3), activation='relu', padding='same') (c1)
c1 = BatchNormalization()(c1)
c1 = Activation('relu')(c1)
#layer 15
c1 = Conv2D(64, (3, 3), activation='relu', padding='same') (c1)
c1 = BatchNormalization()(c1)
c1 = Activation('relu')(c1)
#layer 16
c1 = Conv2D(64, (3, 3), activation='relu', padding='same') (c1)
c1 = BatchNormalization()(c1)
c1 = Activation('relu')(c1)
#layer 17
output_img = Conv2D(1, (1, 1)) (c1)
subtracted = keras.layers.Subtract()([inputs, output_img])


dncnn_bn_model = Model(inputs=[inputs], outputs=[subtracted])
model.compile(optimizer='adam', loss='mse', metrics=[tf_psnr])

dncnn_bn_model.fit(sparseview_60_train, ndct_train, validation_split=0, batch_size=5, epochs=50, callbacks=[history])

reconstructed = dncnn_bn_model.predict(sparseview_60_test)
psnr = cal_psnr(ndct_test, reconstructed)
print("psnr 50 epochs.....",psnr)

a = reconstructed[0].reshape(512, 512)
scalef = np.amax(a)
a = np.clip(255 * a/scalef, 0, 255).astype('uint8')
#result = Image.fromarray((a * 255).astype(np.uint8))                                                                                                
result = Image.fromarray((a).astype(np.uint8))
result.save('rec_dncnn_bn_50.png')
result.save('/content/drive/My Drive/Colab Notebooks/dncnn_keras_colab_notebook/rec_dncnn_bn_50.png')